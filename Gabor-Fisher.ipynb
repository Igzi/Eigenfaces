{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "df5fc43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm \n",
    "from scipy.io import loadmat\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from time import time\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66a80af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the datasets.\"\"\"\n",
    "images = loadmat('images.mat') \n",
    "classes = loadmat('classes')\n",
    "\n",
    "images=images['images'].T  \n",
    "classes=classes['classes'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82a53cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images2d = np.zeros((images.shape[0], 192, 168))\n",
    "for i in range(images.shape[0]):\n",
    "    images2d[i] = images[i].reshape(168, 192).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b9a3c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1689, 192, 168)\n",
      "(1689, 1)\n",
      "(725, 192, 168)\n",
      "(725, 1)\n"
     ]
    }
   ],
   "source": [
    "#replace images and classes with light_images and light_classes for co\n",
    "X_train, X_test, y_train, y_test = train_test_split(images2d, classes, test_size=0.3, random_state=0)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb60b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "def build_gabor_kernels(scales=5, orientations=8, ksize=31, fmax=0.25):\n",
    "    kernels = []\n",
    "    for u in range(scales):\n",
    "        for v in range(orientations):\n",
    "            theta = v * np.pi / orientations\n",
    "            lambd = 1 / (fmax / (2 ** (u / 2)))\n",
    "            kernel = cv2.getGaborKernel((ksize, ksize), sigma=4.0, theta=theta,\n",
    "                                        lambd=lambd, gamma=0.5, psi=0, ktype=cv2.CV_64F)\n",
    "            kernels.append(kernel)\n",
    "    return np.array(kernels)\n",
    "\n",
    "def extract_gabor_features(image, kernels):\n",
    "    feats = []\n",
    "    for kernel in kernels:\n",
    "        filtered = cv2.filter2D(image, cv2.CV_64F, kernel)\n",
    "        feats.append(filtered)\n",
    "    return feats\n",
    "\n",
    "def downsample_features(feats, factor=8):\n",
    "    return np.array([cv2.resize(f, (f.shape[1] // factor, f.shape[0] // factor)).flatten()\n",
    "                     for f in feats]).flatten()\n",
    "\n",
    "def extract_magnitude_features(image, kernels):\n",
    "    mag_feats = []\n",
    "    for kernel in kernels:\n",
    "        filtered = cv2.filter2D(image, cv2.CV_64F, kernel)\n",
    "        real = np.real(filtered)\n",
    "        imag = np.imag(filtered)\n",
    "        magnitude = np.sqrt(real ** 2 + imag ** 2)\n",
    "        mag_feats.append(magnitude)\n",
    "    return downsample_features(mag_feats)\n",
    "\n",
    "def extract_phase_congruency_features(image, kernels, num_orientations=8, num_scales=5, downsample_factor=8, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Extract OGPCI features from a grayscale face image using the standard Gabor kernel bank.\n",
    "\n",
    "    Parameters:\n",
    "        image (2D np.ndarray): Grayscale image (e.g. 128x128).\n",
    "        kernels (list): List of Gabor kernels ordered by scale-major then orientation-minor.\n",
    "        num_orientations (int): Number of orientations (typically 8).\n",
    "        num_scales (int): Number of scales (typically 5).\n",
    "        downsample_factor (int): Factor for downsampling.\n",
    "        epsilon (float): Small constant to avoid division by zero.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: 1D vector of concatenated downsampled OGPCIs (augmented phase congruency feature vector).\n",
    "    \"\"\"\n",
    "    h, w = image.shape\n",
    "    image = image.astype(np.float32)\n",
    "    \n",
    "    # Group kernels by orientation (reshape into [num_orientations][num_scales])\n",
    "    kernel_bank = kernels.reshape((num_scales, num_orientations, 31, 31))\n",
    "    kernel_bank = kernel_bank.transpose((1, 0, 2, 3))\n",
    "\n",
    "    ogpcis = []\n",
    "    \n",
    "    for v, kernel_set in enumerate(kernel_bank):  # loop over orientations\n",
    "        A_sum = np.zeros((h, w), dtype=np.float32)\n",
    "        energy_sum = np.zeros_like(A_sum)\n",
    "\n",
    "        phi_list = []\n",
    "        A_list = []\n",
    "\n",
    "        # Step 1: Compute magnitude and phase for each scale at orientation v\n",
    "        for u in range(num_scales):\n",
    "            kernel = kernel_set[u]\n",
    "            response = cv2.filter2D(image, cv2.CV_64F, kernel)\n",
    "            real = np.real(response)\n",
    "            imag = np.imag(response)\n",
    "\n",
    "            A = np.sqrt(real**2 + imag**2)\n",
    "            phi = np.arctan2(imag, real)\n",
    "\n",
    "            A_list.append(A)\n",
    "            phi_list.append(phi)\n",
    "            A_sum += A\n",
    "\n",
    "        # Step 2: Compute mean phase at this orientation\n",
    "        sin_sum = np.sum([A_list[i] * np.sin(phi_list[i]) for i in range(num_scales)], axis=0)\n",
    "        cos_sum = np.sum([A_list[i] * np.cos(phi_list[i]) for i in range(num_scales)], axis=0)\n",
    "        phi_mean = np.arctan2(sin_sum + epsilon, cos_sum + epsilon)\n",
    "\n",
    "        # Step 3: Compute oriented Gabor phase congruency image (OGPCI)\n",
    "        for u in range(num_scales):\n",
    "            delta_phi = np.cos(phi_list[u] - phi_mean) - np.abs(np.sin(phi_list[u] - phi_mean))\n",
    "            energy_sum += A_list[u] * delta_phi\n",
    "\n",
    "        ogpci = energy_sum / (A_sum + epsilon)\n",
    "\n",
    "        # Step 4: Downsample OGPCI\n",
    "        ogpci_down = cv2.resize(ogpci, (w // downsample_factor, h // downsample_factor)).flatten()\n",
    "        ogpcis.append(ogpci_down)\n",
    "\n",
    "    # Step 5: Concatenate downsampled OGPCIs\n",
    "    return np.concatenate(ogpcis)\n",
    "\n",
    "\n",
    "kernels = build_gabor_kernels()\n",
    "X_train_gabor = [extract_phase_congruency_features(image=img, kernels=kernels) for img in X_train]\n",
    "X_test_gabor = [extract_phase_congruency_features(image=img, kernels=kernels) for img in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9c89d59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train_gabor)\n",
    "X_test_std  = scaler.transform(X_test_gabor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dfd0ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import decomposition\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_pca(X_train, y_train, X_test, y_test, num_components):\n",
    "    pca = decomposition.PCA(n_components=num_components, whiten=True)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, fit_intercept=True)\n",
    "    clf.fit(X_train_pca, y_train.ravel())\n",
    "\n",
    "    y_test_pred = clf.predict(X_test_pca)\n",
    "\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(\"Test f1 score:\", metrics.f1_score(y_test, y_test_pred, average='weighted'))\n",
    "    print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b53fabb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9862068965517241\n",
      "Test f1 score: 0.9863874246033371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.96      0.98        23\n",
      "           2       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       0.95      1.00      0.98        20\n",
      "           5       0.96      1.00      0.98        23\n",
      "           6       1.00      1.00      1.00        11\n",
      "           7       0.95      0.90      0.93        21\n",
      "           8       1.00      1.00      1.00        22\n",
      "           9       1.00      0.96      0.98        24\n",
      "          10       1.00      0.89      0.94        18\n",
      "          11       1.00      0.94      0.97        18\n",
      "          12       1.00      1.00      1.00        22\n",
      "          13       1.00      1.00      1.00        18\n",
      "          14       1.00      1.00      1.00        14\n",
      "          15       1.00      0.96      0.98        24\n",
      "          16       0.93      1.00      0.96        25\n",
      "          17       1.00      1.00      1.00        21\n",
      "          18       0.95      1.00      0.97        18\n",
      "          19       0.80      1.00      0.89        16\n",
      "          20       1.00      1.00      1.00        16\n",
      "          21       1.00      1.00      1.00        19\n",
      "          22       1.00      1.00      1.00        18\n",
      "          23       1.00      1.00      1.00        15\n",
      "          24       1.00      1.00      1.00        21\n",
      "          25       1.00      1.00      1.00        22\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       1.00      1.00      1.00        19\n",
      "          28       1.00      1.00      1.00        18\n",
      "          29       1.00      1.00      1.00        18\n",
      "          30       1.00      1.00      1.00        13\n",
      "          31       1.00      1.00      1.00        16\n",
      "          32       1.00      1.00      1.00        19\n",
      "          33       1.00      1.00      1.00        15\n",
      "          34       1.00      0.94      0.97        16\n",
      "          35       1.00      1.00      1.00        16\n",
      "          36       1.00      1.00      1.00        22\n",
      "          37       1.00      0.97      0.98        32\n",
      "          38       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           0.99       725\n",
      "   macro avg       0.99      0.99      0.99       725\n",
      "weighted avg       0.99      0.99      0.99       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_pca(X_train_std, y_train, X_test_std, y_test, num_components=38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "be9de4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9986206896551724\n",
      "Test f1 score: 0.9986131162284335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        23\n",
      "           2       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      1.00      1.00        20\n",
      "           5       0.96      1.00      0.98        23\n",
      "           6       1.00      1.00      1.00        11\n",
      "           7       1.00      1.00      1.00        21\n",
      "           8       1.00      1.00      1.00        22\n",
      "           9       1.00      1.00      1.00        24\n",
      "          10       1.00      1.00      1.00        18\n",
      "          11       1.00      1.00      1.00        18\n",
      "          12       1.00      1.00      1.00        22\n",
      "          13       1.00      1.00      1.00        18\n",
      "          14       1.00      1.00      1.00        14\n",
      "          15       1.00      1.00      1.00        24\n",
      "          16       1.00      1.00      1.00        25\n",
      "          17       1.00      1.00      1.00        21\n",
      "          18       1.00      1.00      1.00        18\n",
      "          19       1.00      1.00      1.00        16\n",
      "          20       1.00      1.00      1.00        16\n",
      "          21       1.00      1.00      1.00        19\n",
      "          22       1.00      1.00      1.00        18\n",
      "          23       1.00      1.00      1.00        15\n",
      "          24       1.00      1.00      1.00        21\n",
      "          25       1.00      1.00      1.00        22\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       1.00      1.00      1.00        19\n",
      "          28       1.00      1.00      1.00        18\n",
      "          29       1.00      1.00      1.00        18\n",
      "          30       1.00      1.00      1.00        13\n",
      "          31       1.00      1.00      1.00        16\n",
      "          32       1.00      1.00      1.00        19\n",
      "          33       1.00      1.00      1.00        15\n",
      "          34       1.00      0.94      0.97        16\n",
      "          35       1.00      1.00      1.00        16\n",
      "          36       1.00      1.00      1.00        22\n",
      "          37       1.00      1.00      1.00        32\n",
      "          38       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00       725\n",
      "   macro avg       1.00      1.00      1.00       725\n",
      "weighted avg       1.00      1.00      1.00       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_pca(X_train_std, y_train, X_test_std, y_test, num_components=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "41714bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "def evaluate_lda(X_train, y_train, X_test, y_test):\n",
    "    n_classes = len(np.unique(y_train))\n",
    "    n_samples, n_features = X_train.shape\n",
    "    pca = decomposition.PCA(n_components=n_samples - n_classes)\n",
    "    pca.fit(X_train)\n",
    "    X_train_pca = pca.transform(X_train)\n",
    "    W_pca = pca.components_.T\n",
    "\n",
    "    mean_total = np.mean(X_train_pca, axis=0)\n",
    "    S_W = np.zeros((X_train_pca.shape[1], X_train_pca.shape[1]))\n",
    "    S_B = np.zeros_like(S_W)\n",
    "\n",
    "    for cls in np.unique(y_train):\n",
    "        X_cls = X_train_pca[(y_train==cls).flatten(),:]\n",
    "        mean_cls = np.mean(X_cls, axis=0)\n",
    "        S_W += (X_cls - mean_cls).T @ (X_cls - mean_cls)\n",
    "        n_cls = X_cls.shape[0]\n",
    "        diff = (mean_cls - mean_total).reshape(-1, 1)\n",
    "        S_B += n_cls * (diff @ diff.T)\n",
    "\n",
    "    eigvals, eigvecs = np.linalg.eig(np.linalg.pinv(S_W) @ S_B)\n",
    "    idx = np.argsort(-eigvals.real)\n",
    "    eigvecs = eigvecs[:, idx]\n",
    "    W_fld = eigvecs[:, :n_classes - 1].real\n",
    "    W_fisher = W_pca @ W_fld\n",
    "\n",
    "    X_train_fisher = X_train @ W_fisher\n",
    "    X_test_fisher  = X_test @ W_fisher\n",
    "\n",
    "    clf = LogisticRegression(max_iter=2000, fit_intercept=True)\n",
    "    clf.fit(X_train_fisher, y_train.ravel())\n",
    "\n",
    "    y_test_pred = clf.predict(X_test_fisher)\n",
    "\n",
    "    print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "    print(\"Test f1 score:\", metrics.f1_score(y_test, y_test_pred, average='weighted'))\n",
    "    print(metrics.classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae7bdddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9972413793103448\n",
      "Test f1 score: 0.9972416652018101\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        23\n",
      "           2       1.00      1.00      1.00        13\n",
      "           3       1.00      1.00      1.00        18\n",
      "           4       1.00      0.95      0.97        20\n",
      "           5       0.96      1.00      0.98        23\n",
      "           6       1.00      1.00      1.00        11\n",
      "           7       1.00      1.00      1.00        21\n",
      "           8       1.00      1.00      1.00        22\n",
      "           9       1.00      1.00      1.00        24\n",
      "          10       1.00      1.00      1.00        18\n",
      "          11       1.00      1.00      1.00        18\n",
      "          12       1.00      1.00      1.00        22\n",
      "          13       1.00      1.00      1.00        18\n",
      "          14       1.00      1.00      1.00        14\n",
      "          15       1.00      1.00      1.00        24\n",
      "          16       1.00      1.00      1.00        25\n",
      "          17       1.00      1.00      1.00        21\n",
      "          18       1.00      1.00      1.00        18\n",
      "          19       1.00      1.00      1.00        16\n",
      "          20       1.00      1.00      1.00        16\n",
      "          21       1.00      1.00      1.00        19\n",
      "          22       1.00      1.00      1.00        18\n",
      "          23       1.00      1.00      1.00        15\n",
      "          24       1.00      1.00      1.00        21\n",
      "          25       1.00      1.00      1.00        22\n",
      "          26       1.00      1.00      1.00        22\n",
      "          27       1.00      1.00      1.00        19\n",
      "          28       1.00      1.00      1.00        18\n",
      "          29       1.00      1.00      1.00        18\n",
      "          30       0.93      1.00      0.96        13\n",
      "          31       1.00      1.00      1.00        16\n",
      "          32       1.00      1.00      1.00        19\n",
      "          33       1.00      1.00      1.00        15\n",
      "          34       1.00      0.94      0.97        16\n",
      "          35       1.00      1.00      1.00        16\n",
      "          36       1.00      1.00      1.00        22\n",
      "          37       1.00      1.00      1.00        32\n",
      "          38       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00       725\n",
      "   macro avg       1.00      1.00      1.00       725\n",
      "weighted avg       1.00      1.00      1.00       725\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_lda(X_train_std, y_train, X_test_std, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
